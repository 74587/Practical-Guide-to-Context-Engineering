# Cipherçš„LLM æœåŠ¡æ¶æ„åˆ†ææ–‡æ¡£ -TSç‰ˆæœ¬
**ğŸ¤– æœ¬æ–‡æ¡£æ˜¯ç”±AIå¤§æ¨¡å‹æ•´ç†ï¼Œä½œä¸ºLLMæ¨¡å—Tsç‰ˆæœ¬çš„å®ç°å…·ä½“çš„å‚è€ƒ**
## ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æ ¸å¿ƒæ¥å£å®šä¹‰](#æ ¸å¿ƒæ¥å£å®šä¹‰)
3. [Factory å·¥å‚æ¨¡å¼å®ç°](#factory-å·¥å‚æ¨¡å¼å®ç°)
4. [å„ LLM æœåŠ¡ç±»è¯¦ç»†åˆ†æ](#å„-llm-æœåŠ¡ç±»è¯¦ç»†åˆ†æ)
5. [æ•°æ®æ ¼å¼åŒ–è§„èŒƒ](#æ•°æ®æ ¼å¼åŒ–è§„èŒƒ)
6. [é…ç½®ç»“æ„](#é…ç½®ç»“æ„)

---

## æ¦‚è¿°

Cipher é¡¹ç›®é‡‡ç”¨ç»Ÿä¸€çš„ LLM æœåŠ¡æ¶æ„ï¼Œæ”¯æŒå¤šç§ LLM æä¾›å•†ã€‚æ‰€æœ‰æœåŠ¡ç±»éƒ½å®ç°äº† `ILLMService` æ¥å£ï¼Œé€šè¿‡å·¥å‚æ¨¡å¼è¿›è¡Œå®ä¾‹åŒ–å’Œç®¡ç†ã€‚

**æ”¯æŒçš„ LLM æä¾›å•†ï¼š**
- OpenAI
- Anthropic (Claude)
- AWS Bedrock
- Azure OpenAI
- Google Gemini
- Qwen (é€šä¹‰åƒé—®)
- Ollama (æœ¬åœ°)
- OpenRouter
- LM Studio (æœ¬åœ°)
- DeepSeek

---

## æ ¸å¿ƒæ¥å£å®šä¹‰

### ILLMService æ¥å£

æ‰€æœ‰ LLM æœåŠ¡å¿…é¡»å®ç°ä»¥ä¸‹æ¥å£ï¼š

```typescript
export interface ILLMService {
  // ä¸»è¦ç”Ÿæˆæ–¹æ³• - ä½¿ç”¨ä¼šè¯ä¸Šä¸‹æ–‡
  generate(userInput: string, imageData?: ImageData, stream?: boolean): Promise<string>;
  
  // ç›´æ¥ç”Ÿæˆæ–¹æ³• - ä¸ä½¿ç”¨ä¼šè¯ä¸Šä¸‹æ–‡ï¼Œç”¨äºå†…éƒ¨å·¥å…·æ“ä½œ
  directGenerate(userInput: string, systemPrompt?: string): Promise<string>;
  
  // è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
  getAllTools(): Promise<ToolSet>;
  
  // è·å–æœåŠ¡é…ç½®
  getConfig(): LLMServiceConfig;
}
```

### LLMServiceConfig ç±»å‹

```typescript
export type LLMServiceConfig = {
  provider: string;  // æä¾›å•†åç§°
  model: string;     // æ¨¡å‹åç§°
};
```

---

## Factory å·¥å‚æ¨¡å¼å®ç°

### createLLMService æ–¹æ³•

å…¬å…±æ–¹æ³•ï¼Œç”¨äºåˆ›å»ºå¹¶é…ç½® LLM æœåŠ¡å®ä¾‹ã€‚

```typescript
export function createLLMService(
  config: LLMConfig,
  mcpManager: MCPManager,
  contextManager: ContextManager,
  unifiedToolManager?: UnifiedToolManager,
  eventManager?: any
): ILLMService {
  // 1. è°ƒç”¨å†…éƒ¨æ–¹æ³•åˆ›å»ºæœåŠ¡å®ä¾‹
  const service = _createLLMService(config, mcpManager, contextManager, unifiedToolManager);

  // 2. è®¾ç½®äº‹ä»¶ç®¡ç†å™¨ï¼ˆå¦‚æœæä¾›ï¼‰
  if (eventManager && typeof (service as any).setEventManager === 'function') {
    (service as any).setEventManager(eventManager);
  }

  // 3. é…ç½® token-aware å‹ç¼©
  configureCompressionForService(config, contextManager);

  return service;
}
```

**å…³é”®åŠŸèƒ½ï¼š**
1. åˆ›å»ºæœåŠ¡å®ä¾‹
2. æ³¨å…¥äº‹ä»¶ç®¡ç†å™¨ç”¨äºç›‘æ§å’Œæ—¥å¿—
3. é…ç½®ä¸Šä¸‹æ–‡å‹ç¼©ä»¥ä¼˜åŒ– token ä½¿ç”¨

### _createLLMService æ–¹æ³•

å†…éƒ¨æ–¹æ³•ï¼Œæ ¹æ®é…ç½®åˆ›å»ºå…·ä½“çš„ LLM æœåŠ¡å®ä¾‹ã€‚

```typescript
function _createLLMService(
  config: LLMConfig,
  mcpManager: MCPManager,
  contextManager: ContextManager,
  unifiedToolManager?: UnifiedToolManager
): ILLMService {
  // 1. æå–å¹¶éªŒè¯ API Key
  const apiKey = extractApiKey(config);

  // 2. æ ¹æ® provider åˆ›å»ºå¯¹åº”æœåŠ¡
  switch (config.provider.toLowerCase()) {
    case 'openai': {
      const baseURL = getOpenAICompatibleBaseURL(config);
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({ apiKey, ...(baseURL ? { baseURL } : {}) });
      return new OpenAIService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'anthropic': {
      const AnthropicClass = require('@anthropic-ai/sdk');
      const anthropic = new AnthropicClass({ apiKey });
      return new AnthropicService(
        anthropic,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'gemini': {
      return new GeminiService(
        apiKey,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'aws': {
      return new AwsService(
        config.model,
        mcpManager,
        contextManager,
        unifiedToolManager,
        config.maxIterations,
        config.aws
      );
    }
    
    case 'azure': {
      return new AzureService(
        config.model,
        mcpManager,
        contextManager,
        unifiedToolManager,
        config.maxIterations,
        config.azure
      );
    }
    
    case 'qwen': {
      const baseURL = config.baseURL || 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1';
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({ apiKey, baseURL });
      const qwenOptions: QwenOptions = {
        ...(config.qwenOptions?.enableThinking !== undefined && {
          enableThinking: config.qwenOptions.enableThinking,
        }),
        ...(config.qwenOptions?.thinkingBudget !== undefined && {
          thinkingBudget: config.qwenOptions.thinkingBudget,
        }),
        ...(config.qwenOptions?.temperature !== undefined && {
          temperature: config.qwenOptions.temperature,
        }),
        ...(config.qwenOptions?.top_p !== undefined && { 
          top_p: config.qwenOptions.top_p 
        }),
      };
      return new QwenService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        qwenOptions,
        unifiedToolManager
      );
    }
    
    case 'ollama': {
      const baseURL = getOpenAICompatibleBaseURL(config);
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({
        apiKey: 'not-required',
        baseURL,
      });
      return new OllamaService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'openrouter': {
      const baseURL = getOpenAICompatibleBaseURL(config);
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({
        apiKey,
        baseURL,
        defaultHeaders: {
          'HTTP-Referer': 'https://github.com/byterover/cipher',
          'X-Title': 'Cipher Memory Agent',
        },
      });
      return new OpenRouterService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'lmstudio': {
      const baseURL = getOpenAICompatibleBaseURL(config);
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({
        apiKey: 'lm-studio',
        baseURL,
      });
      return new LMStudioService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    case 'deepseek': {
      const baseURL = getOpenAICompatibleBaseURL(config);
      const OpenAIClass = require('openai');
      const openai = new OpenAIClass({ apiKey, baseURL });
      return new DeepseekService(
        openai,
        config.model,
        mcpManager,
        contextManager,
        config.maxIterations,
        unifiedToolManager
      );
    }
    
    default:
      throw new Error(`Unsupported LLM provider: ${config.provider}`);
  }
}
```

### è¾…åŠ©å·¥å…·å‡½æ•°

#### extractApiKey
æå–å¹¶éªŒè¯ API Keyã€‚

```typescript
function extractApiKey(config: LLMConfig): string {
  const provider = config.provider.toLowerCase();

  // æ— éœ€ API Key çš„æä¾›å•†
  if (
    provider === 'ollama' ||
    provider === 'lmstudio' ||
    provider === 'aws' ||
    provider === 'azure'
  ) {
    return 'not-required';
  }

  let apiKey = config.apiKey || '';
  if (!apiKey) {
    throw new Error(`Error: API key for ${provider} not found`);
  }
  
  return apiKey;
}
```

#### getOpenAICompatibleBaseURL
è·å–å…¼å®¹ OpenAI API çš„ Base URLã€‚

```typescript
function getOpenAICompatibleBaseURL(llmConfig: LLMConfig): string {
  if (llmConfig.baseURL) {
    let baseUrl = llmConfig.baseURL.replace(/\/$/, '');
    
    // ä¸º Ollama ç¡®ä¿ /v1 åç¼€
    const provider = llmConfig.provider.toLowerCase();
    if (provider === 'ollama' && !baseUrl.endsWith('/v1') && !baseUrl.endsWith('/api')) {
      baseUrl = baseUrl + '/v1';
    }
    
    return baseUrl;
  }

  const provider = llmConfig.provider.toLowerCase();

  // æä¾›å•†é»˜è®¤å€¼
  if (provider === 'openrouter') {
    return 'https://openrouter.ai/api/v1';
  }
  
  if (provider === 'ollama') {
    let baseUrl = env.OLLAMA_BASE_URL || 'http://localhost:11434/v1';
    if (!baseUrl.endsWith('/v1') && !baseUrl.endsWith('/api')) {
      baseUrl = baseUrl.replace(/\/$/, '') + '/v1';
    }
    return baseUrl;
  }
  
  if (provider === 'lmstudio') {
    return env.LMSTUDIO_BASE_URL || 'http://localhost:1234/v1';
  }
  
  if (provider === 'openai' && env.OPENAI_BASE_URL) {
    return env.OPENAI_BASE_URL.replace(/\/$/, '');
  }
  
  if (provider === 'deepseek') {
    return 'https://api.deepseek.com';
  }

  return '';
}
```

#### getDefaultContextWindow
è·å–é»˜è®¤ä¸Šä¸‹æ–‡çª—å£å¤§å°ã€‚

```typescript
function getDefaultContextWindow(provider: string, model?: string): number {
  const defaults: Record<string, Record<string, number>> = {
    openai: {
      'gpt-3.5-turbo': 16385,
      'gpt-4': 8192,
      'gpt-4-32k': 32768,
      'gpt-4-turbo': 128000,
      'gpt-4o': 128000,
      'gpt-4o-mini': 128000,
      'o1-preview': 128000,
      'o1-mini': 128000,
      default: 8192,
    },
    anthropic: {
      'claude-3-opus': 200000,
      'claude-3-sonnet': 200000,
      'claude-3-haiku': 200000,
      'claude-3-5-sonnet': 200000,
      'claude-2.1': 200000,
      'claude-2.0': 100000,
      'claude-instant-1.2': 100000,
      default: 200000,
    },
    gemini: {
      'gemini-pro': 32760,
      'gemini-pro-vision': 16384,
      'gemini-ultra': 32760,
      'gemini-1.5-pro': 1000000,
      'gemini-1.5-flash': 1000000,
      'gemini-1.5-pro-latest': 2000000,
      'gemini-1.5-flash-latest': 1000000,
      'gemini-2.0-flash': 1000000,
      'gemini-2.0-flash-exp': 1000000,
      'gemini-2.5-pro': 2000000,
      'gemini-2.5-flash': 1000000,
      'gemini-2.5-flash-lite': 1000000,
      default: 1000000,
    },
    deepseek: {
      default: 128000,
    },
    ollama: {
      default: 8192,
    },
    openrouter: {
      default: 8192,
    },
  };

  const providerDefaults = defaults[provider];
  if (!providerDefaults) {
    return 8192; // å…¨å±€é»˜è®¤å€¼
  }

  return providerDefaults[model || 'default'] || providerDefaults.default || 8192;
}
```

---

## å„ LLM æœåŠ¡ç±»è¯¦ç»†åˆ†æ

### 1. OpenAI Service

**æ”¯æŒçš„æä¾›å•†:** OpenAI, OpenRouter, Ollama, LM Studio, DeepSeek

**å·¥å…·æ ¼å¼åŒ– (OpenAI æ ‡å‡†æ ¼å¼):**
```typescript
{
  type: 'function',
  function: {
    name: string,
    description: string,
    parameters: JSONSchema
  }
}
```

**API è°ƒç”¨æ ¼å¼:**
```typescript
await openai.chat.completions.create({
  model: this.model,
  messages: formattedMessages,  // æ ‡å‡†æ¶ˆæ¯æ•°ç»„
  tools: tools,                  // å·¥å…·æ•°ç»„
  tool_choice: 'auto'           // å·¥å…·é€‰æ‹©ç­–ç•¥
});
```

**æ¶ˆæ¯æ ¼å¼:**
```typescript
{
  role: 'system' | 'user' | 'assistant' | 'tool',
  content: string,
  tool_calls?: Array<{
    id: string,
    type: 'function',
    function: {
      name: string,
      arguments: string  // JSON å­—ç¬¦ä¸²
    }
  }>,
  tool_call_id?: string,  // ä»…ç”¨äº tool è§’è‰²
  name?: string           // ä»…ç”¨äº tool è§’è‰²
}
```

**ç‰¹æ€§:**
- âœ… æ”¯æŒå·¥å…·è°ƒç”¨ (Function Calling)
- âœ… æ”¯æŒå›¾åƒè¾“å…¥
- âœ… é‡è¯•æœºåˆ¶ (æœ€å¤š 3 æ¬¡)
- âœ… ä¸Šä¸‹æ–‡å‹ç¼©
- âœ… äº‹ä»¶å‘å°„ (å¼€å§‹ã€æ€è€ƒã€å®Œæˆã€é”™è¯¯)

### 2. Anthropic Service

**å·¥å…·æ ¼å¼åŒ– (Anthropic æ ¼å¼):**
```typescript
{
  name: string,
  description: string,
  input_schema: {
    type: 'object',
    properties: { ... },
    required: string[]
  }
}
```

**API è°ƒç”¨æ ¼å¼:**
```typescript
await anthropic.messages.create({
  model: this.model,
  messages: nonSystemMessages,  // ä¸åŒ…å« system çš„æ¶ˆæ¯
  system: systemPrompt,         // å•ç‹¬çš„ system å­—æ®µ
  tools: tools,
  max_tokens: 4096
});
```

**æ¶ˆæ¯æ ¼å¼:**
```typescript
{
  role: 'user' | 'assistant',
  content: Array<{
    type: 'text' | 'tool_use' | 'tool_result',
    text?: string,
    id?: string,
    name?: string,
    input?: object,
    tool_use_id?: string,
    content?: string
  }>
}
```

**ç‰¹æ®Šå¤„ç†:**
- System prompt ç‹¬ç«‹å¤„ç†ï¼Œä¸åœ¨æ¶ˆæ¯æ•°ç»„ä¸­
- Tool use å’Œ tool result ä½œä¸º content blocks
- éœ€è¦å°† tool_use è½¬æ¢ä¸ºæ ‡å‡† tool_calls æ ¼å¼

**é‡è¯•ç­–ç•¥:**
```typescript
// å¯é‡è¯•é”™è¯¯
- 429 (Rate Limit)
- 500+ (Server Errors)
- 529 (Overloaded)
- Network errors

// ä¸å¯é‡è¯•é”™è¯¯
- 400 (Invalid Request)
- 401 (Authentication)
- 403 (Permission Denied)
- 404 (Not Found)

// æŒ‡æ•°é€€é¿ + æŠ–åŠ¨
delay = min(2^attempt * baseDelay * jitter, 30000ms)
```

### 3. Google Gemini Service

**å·¥å…·æ ¼å¼åŒ– (ç±» OpenAI æ ¼å¼ï¼Œä½†ä½¿ç”¨æç¤ºè¯æ³¨å…¥):**

Gemini ä¸ä½¿ç”¨åŸç”Ÿ Function Calling APIï¼Œè€Œæ˜¯é€šè¿‡ç‰¹æ®Šæ ¼å¼çš„æç¤ºè¯æ¥å®ç°å·¥å…·è°ƒç”¨ï¼š

```typescript
// æç¤ºè¯ä¸­çš„å·¥å…·æè¿°æ ¼å¼
Tool: tool_name
Description: tool description
Parameters: {json_schema}

// å·¥å…·è°ƒç”¨å“åº”æ ¼å¼
{
  "tool": "tool_name",
  "arguments": {
    "param1": "value1"
  }
}
```

**æ¶ˆæ¯è½¬æ¢:**
```typescript
// å°†æ¶ˆæ¯æ•°ç»„è½¬æ¢ä¸ºæ–‡æœ¬æç¤º
User: {user_message}
Assistant: {assistant_message}
System: {system_message}
```

**å·¥å…·è°ƒç”¨è§£æ:**
```typescript
private parseGeminiResponse(text: string): any {
  // 1. æŸ¥æ‰¾å·¥å…·è°ƒç”¨ä»£ç å—
  const toolCallPattern = /```tool_code\s*\n?([^`]*)\n?```/gi;
  
  // 2. è§£æ JSON
  const toolCallData = JSON.parse(match[1].trim());
  
  // 3. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
  return {
    id: `gemini_${Date.now()}_${randomId}`,
    type: 'function',
    function: {
      name: toolCallData.tool,
      arguments: JSON.stringify(toolCallData.arguments)
    }
  };
}
```

**ç‰¹æ®ŠåŠŸèƒ½:**
- æ¸…ç†å·¥å…·å…ƒæ•°æ® (cleanToolMetadata)
- é˜²æ­¢é‡å¤å·¥å…·è°ƒç”¨
- è‡ªå®šä¹‰å·¥å…·è°ƒç”¨æ ¼å¼

### 4. AWS Bedrock Service

**æ”¯æŒçš„æ¨¡å‹ç³»åˆ—:**
```typescript
enum ModelFamily {
  ANTHROPIC = 'anthropic',
  META_LLAMA = 'meta',
  AMAZON_TITAN = 'amazon.titan',
  AMAZON_NOVA = 'amazon.nova',
  AI21_LABS = 'ai21',
  COHERE = 'cohere',
  DEEPSEEK = 'deepseek',
  LUMA_AI = 'luma',
  MISTRAL_AI = 'mistral',
  STABILITY_AI = 'stability',
  TWELVELABS = 'twelvelabs',
  WRITER = 'writer',
}
```

**æ ¹æ®æ¨¡å‹ç³»åˆ—é€‰æ‹©ä¸åŒçš„æ ¼å¼åŒ–å™¨:**
```typescript
switch (this.modelFamily) {
  case ModelFamily.ANTHROPIC:
    this.formatter = new BedrockAnthropicMessageFormatter();
    break;
  case ModelFamily.META_LLAMA:
    this.formatter = new BedrockLlamaMessageFormatter();
    break;
  case ModelFamily.AMAZON_TITAN:
    this.formatter = new BedrockTitanMessageFormatter();
    break;
  case ModelFamily.DEEPSEEK:
    this.formatter = new BedrockDeepSeekMessageFormatter();
    break;
  case ModelFamily.AI21_LABS:
    this.formatter = new BedrockAI21MessageFormatter();
    break;
  default:
    this.formatter = new BedrockAnthropicMessageFormatter();
}
```

**API è°ƒç”¨ (Anthropic æ ¼å¼ç¤ºä¾‹):**
```typescript
const request = {
  messages: formattedMessages,
  anthropic_version: 'bedrock-2023-05-31',
  max_tokens: 4096,
  temperature: 0.7,
  ...(systemPrompt ? { system: systemPrompt } : {}),
  ...(tools.length > 0 ? { 
    tools: tools,
    tool_choice: { type: 'auto' }
  } : {})
};

const command = new InvokeModelCommand({
  modelId: this.model,
  contentType: 'application/json',
  accept: 'application/json',
  body: JSON.stringify(request),
  ...(inferenceProfileArn ? { 
    inferenceConfig: { profileId: inferenceProfileArn } 
  } : {})
});
```

**AWS é…ç½®:**
```typescript
{
  region: 'us-east-1',
  credentials: {
    accessKeyId: string,
    secretAccessKey: string,
    sessionToken?: string  // å¯é€‰
  },
  inferenceProfileArn?: string  // é¢„ç½®ååé‡ ARN
}
```

### 5. Azure OpenAI Service

**å·¥å…·æ ¼å¼åŒ– (OpenAI å…¼å®¹):**
```typescript
{
  type: 'function',
  function: {
    name: string,
    description: string,
    parameters: JSONSchema
  }
}
```

**API è°ƒç”¨ (ä½¿ç”¨ Azure SDK):**
```typescript
await this.client.getChatCompletions(
  this.deploymentName,  // Azure éƒ¨ç½²åç§°
  formattedMessages,
  {
    temperature: 0.7,
    maxTokens: 4096,
    topP: 1,
    tools: tools,
    toolChoice: 'auto'  // æ³¨æ„ï¼šAzure ä½¿ç”¨ toolChoice è€Œé tool_choice
  }
);
```

**æ¶ˆæ¯æ ¼å¼å½’ä¸€åŒ–:**
```typescript
// Azure å¯èƒ½è¿”å›ä¸åŒæ ¼å¼çš„ tool calls
const normalizedMessage = {
  ...message,
  tool_calls: 
    message.toolCalls ||        // Azure æ ¼å¼
    message.tool_calls ||       // OpenAI æ ¼å¼
    (message.functionCall ? [{  // æ—§ç‰ˆ function call æ ¼å¼
      id: `call_${Date.now()}`,
      type: 'function',
      function: {
        name: message.functionCall.name,
        arguments: message.functionCall.arguments,
      },
    }] : undefined)
};
```

**é…ç½®è¦æ±‚:**
```typescript
{
  endpoint: 'https://{resource-name}.openai.azure.com',
  deploymentName: string,  // éƒ¨ç½²åç§°ï¼Œé»˜è®¤ä½¿ç”¨ model
  apiKey: string           // AZURE_OPENAI_API_KEY
}
```

### 6. Qwen Service

**ç‰¹æ®Šé…ç½®é€‰é¡¹:**
```typescript
interface QwenOptions {
  enableThinking?: boolean,      // å¯ç”¨æ€è€ƒæ¨¡å¼
  thinkingBudget?: number,       // æ€è€ƒ token é¢„ç®—
  temperature?: number,           // æ¸©åº¦å‚æ•° [0-2]
  top_p?: number                  // Top-P å‚æ•° [0-1]
}
```

**é…ç½®è½¬æ¢ (camelCase â†’ snake_case):**
```typescript
const apiOptions: any = {
  enable_thinking: this.qwenOptions.enableThinking ?? false,
  thinking_budget: this.qwenOptions.thinkingBudget,
  temperature: this.qwenOptions.temperature,
  top_p: this.qwenOptions.top_p
};
```

**API è°ƒç”¨:**
```typescript
await this.openai.chat.completions.create({
  model: this.model,
  messages: formattedMessages,
  tools: tools,
  tool_choice: 'auto',
  ...apiOptions  // Qwen ç‰¹å®šé€‰é¡¹
});
```

**ç‰¹æ€§:**
- ä½¿ç”¨ OpenAI SDK (å…¼å®¹æ ¼å¼)
- é»˜è®¤ endpoint: `https://dashscope-intl.aliyuncs.com/compatible-mode/v1`
- æ”¯æŒæ€è€ƒæ¨¡å¼ (thinking mode)

---

## æ•°æ®æ ¼å¼åŒ–è§„èŒƒ

### ç»Ÿä¸€å·¥å…·è°ƒç”¨æ ¼å¼

æ‰€æœ‰æœåŠ¡éƒ½å°†å·¥å…·è°ƒç”¨è½¬æ¢ä¸ºä»¥ä¸‹æ ‡å‡†æ ¼å¼ï¼š

```typescript
{
  id: string,           // å·¥å…·è°ƒç”¨ ID
  type: 'function',     // å›ºå®šä¸º 'function'
  function: {
    name: string,       // å·¥å…·åç§°
    arguments: string   // JSON å­—ç¬¦ä¸²åŒ–çš„å‚æ•°
  }
}
```

### å·¥å…·ç»“æœæ ¼å¼

```typescript
{
  role: 'tool',
  tool_call_id: string,  // å¯¹åº”çš„å·¥å…·è°ƒç”¨ ID
  name: string,          // å·¥å…·åç§°
  content: string        // ç»“æœå†…å®¹ (JSON æˆ–æ–‡æœ¬)
}
```


### æ¶ˆæ¯æ ¼å¼è½¬æ¢æµç¨‹

```
1. ç”¨æˆ·è¾“å…¥ â†’ addUserMessage()
   â†“
2. è·å–æ ¼å¼åŒ–æ¶ˆæ¯ â†’ getFormattedMessage()
   â†“
3. æ·»åŠ ç³»ç»Ÿæç¤º â†’ getSystemPrompt()
   â†“
4. å‹ç¼©å†å²è®°å½• â†’ compressHistory() (å¦‚æœè¶…å‡ºé™åˆ¶)
   â†“
5. è½¬æ¢ä¸ºæä¾›å•†æ ¼å¼ â†’ å„æœåŠ¡çš„æ ¼å¼åŒ–æ–¹æ³•
   â†“
6. è°ƒç”¨ LLM API
   â†“
7. è§£æå“åº” â†’ æ ‡å‡†åŒ–å·¥å…·è°ƒç”¨æ ¼å¼
   â†“
8. æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯ â†’ addAssistantMessage()
   â†“
9. æ‰§è¡Œå·¥å…· (å¦‚æœæœ‰)
   â†“
10. æ·»åŠ å·¥å…·ç»“æœ â†’ addToolResult()
   â†“
11. å¾ªç¯ (ç›´åˆ°æ— å·¥å…·è°ƒç”¨æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£)
```

### å„æä¾›å•†å·¥å…·æ ¼å¼å¯¹æ¯”

| æä¾›å•† | å·¥å…·å®šä¹‰æ ¼å¼ | ç‰¹æ®Šå¤„ç† |
|--------|------------|---------|
| OpenAI | `{type: 'function', function: {...}}` | æ ‡å‡†æ ¼å¼ |
| Anthropic | `{name, description, input_schema}` | System prompt ç‹¬ç«‹ |
| Gemini | æç¤ºè¯æ³¨å…¥ | è§£æ tool_code ä»£ç å— |
| AWS Bedrock | æ ¹æ®æ¨¡å‹ç³»åˆ—ä¸åŒ | å¤šç§æ ¼å¼åŒ–å™¨ |
| Azure | OpenAI å…¼å®¹ | toolChoice vs tool_choice |
| Qwen | OpenAI å…¼å®¹ | ç‰¹æ®Šé€‰é¡¹è½¬æ¢ |
| Ollama | OpenAI å…¼å®¹ | æœ¬åœ°æ—  API Key |
| OpenRouter | OpenAI å…¼å®¹ | è‡ªå®šä¹‰ headers |
| LM Studio | OpenAI å…¼å®¹ | æœ¬åœ°ï¼ŒAPI Key å›ºå®š |
| DeepSeek | OpenAI å…¼å®¹ | æ ‡å‡†æ ¼å¼ |

---

## é…ç½®ç»“æ„

### LLMConfig Schema

```typescript
{
  provider: string,        // æä¾›å•†åç§°
  model: string,          // æ¨¡å‹åç§°
  apiKey?: string,        // API Key (å¯é€‰ï¼Œæ”¯æŒ $VAR ç¯å¢ƒå˜é‡)
  maxIterations?: number, // æœ€å¤§è¿­ä»£æ¬¡æ•° (é»˜è®¤ 50)
  baseURL?: string,       // è‡ªå®šä¹‰ Base URL
  
  // Qwen ç‰¹å®šé…ç½®
  qwenOptions?: {
    enableThinking?: boolean,
    thinkingBudget?: number,
    temperature?: number,
    top_p?: number
  },
  
  // AWS ç‰¹å®šé…ç½®
  aws?: {
    region?: string,
    accessKeyId?: string,
    secretAccessKey?: string,
    sessionToken?: string,
    inferenceProfileArn?: string
  },
  
  // Azure ç‰¹å®šé…ç½®
  azure?: {
    endpoint: string,           // å¿…éœ€
    deploymentName?: string     // å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ model
  }
}
```

### éªŒè¯è§„åˆ™

```typescript
// æ”¯æŒçš„æä¾›å•†
const supportedProviders = [
  'openai', 'anthropic', 'openrouter', 'ollama', 
  'lmstudio', 'qwen', 'aws', 'azure', 'gemini', 'deepseek'
];

// æ— éœ€ API Key çš„æä¾›å•†
const noApiKeyRequired = ['ollama', 'lmstudio', 'aws'];

// AWS å¿…é¡»æä¾› aws é…ç½®å¯¹è±¡
// Azure å¿…é¡»æä¾› azure é…ç½®å¯¹è±¡å’Œ endpoint
// å…¶ä»–æä¾›å•†å¿…é¡»æä¾› apiKey
```

### ç¯å¢ƒå˜é‡æ”¯æŒ

```bash
# OpenAI
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Gemini
GEMINI_API_KEY=...

# Qwen
QWEN_API_KEY=sk-...

# AWS
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_SESSION_TOKEN=...
AWS_DEFAULT_REGION=us-east-1
AWS_BEDROCK_INFERENCE_PROFILE_ARN=...

# Azure
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_ENDPOINT=https://...

# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# LM Studio
LMSTUDIO_BASE_URL=http://localhost:1234/v1

# OpenRouter
OPENROUTER_API_KEY=...

# DeepSeek
DEEPSEEK_API_KEY=...
```

---

## å…³é”®è®¾è®¡æ¨¡å¼

### 1. å·¥å‚æ¨¡å¼
æ‰€æœ‰æœåŠ¡é€šè¿‡ Factory åˆ›å»ºï¼Œç»Ÿä¸€é…ç½®å’Œåˆå§‹åŒ–æµç¨‹ã€‚

### 2. ç­–ç•¥æ¨¡å¼
ä¸åŒæä¾›å•†å®ç°ç›¸åŒæ¥å£ï¼Œä½†æœ‰ä¸åŒçš„å®ç°ç­–ç•¥ã€‚

### 3. é€‚é…å™¨æ¨¡å¼
- OpenAI SDK é€‚é… â†’ Ollama, OpenRouter, LM Studio, Qwen, DeepSeek
- Azure SDK é€‚é… â†’ Azure OpenAI
- Gemini SDK é€‚é… â†’ Google Gemini
- AWS SDK é€‚é… â†’ AWS Bedrock (å¤šæ¨¡å‹)

### 4. æ¨¡æ¿æ–¹æ³•æ¨¡å¼
æ‰€æœ‰æœåŠ¡å…±äº«ç›¸åŒçš„ generate æµç¨‹ï¼š
1. æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
2. è·å–å·¥å…·
3. å¾ªç¯ç›´åˆ°å®Œæˆæˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£
4. å¤„ç†å·¥å…·è°ƒç”¨
5. è¿”å›ç»“æœ

### 5. è§‚å¯Ÿè€…æ¨¡å¼
äº‹ä»¶å‘å°„æœºåˆ¶å…è®¸å¤–éƒ¨ç›‘æ§ï¼š
- LLM_RESPONSE_STARTED
- LLM_THINKING
- LLM_RESPONSE_COMPLETED
- LLM_RESPONSE_ERROR

---

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
```typescript
// é‡è¯•æœºåˆ¶
const MAX_ATTEMPTS = 3;
for (let attempt = 1; attempt <= MAX_ATTEMPTS; attempt++) {
  try {
    // API è°ƒç”¨
  } catch (error) {
    if (attempt === MAX_ATTEMPTS) throw error;
    await sleep(500 * attempt);  // æŒ‡æ•°é€€é¿
  }
}
```

### 2. ä¸Šä¸‹æ–‡ç®¡ç†
```typescript
// è‡ªåŠ¨å‹ç¼©é•¿ä¸Šä¸‹æ–‡
if (tokenCount > contextWindow * 0.8) {
  await contextManager.compressHistory();
}
```

### 3. å·¥å…·è°ƒç”¨ä¼˜åŒ–
```typescript
// é¦–æ¬¡å°è¯•æä¾›å·¥å…·ï¼Œé‡è¯•æ—¶ç¦ç”¨å·¥å…·
tools: attempt === 1 ? tools : [],
tool_choice: attempt === 1 ? 'auto' : 'none'
```

### 4. æ—¥å¿—è®°å½•
```typescript
logger.debug('å‘é€æ¶ˆæ¯åˆ° LLM');
logger.info('ğŸ”§ ä½¿ç”¨å·¥å…·: tool_name');
logger.silly('å®Œæ•´å“åº”:', response);
logger.error('API è°ƒç”¨å¤±è´¥', error);
```

---

## æ€»ç»“

Cipher çš„ LLM æœåŠ¡æ¶æ„å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

âœ… **ç»Ÿä¸€æ¥å£** - æ‰€æœ‰æä¾›å•†å®ç°ç›¸åŒæ¥å£  
âœ… **çµæ´»é…ç½®** - æ”¯æŒå¤šç§é…ç½®æ–¹å¼å’Œç¯å¢ƒå˜é‡  
âœ… **å¼ºå¤§å…¼å®¹æ€§** - æ”¯æŒ 10+ LLM æä¾›å•†  
âœ… **æ™ºèƒ½é‡è¯•** - å†…ç½®é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†  
âœ… **ä¸Šä¸‹æ–‡ä¼˜åŒ–** - è‡ªåŠ¨å‹ç¼©å’Œ token ç®¡ç†  
âœ… **å·¥å…·é›†æˆ** - ç»Ÿä¸€çš„å·¥å…·è°ƒç”¨æ¥å£  
âœ… **äº‹ä»¶é©±åŠ¨** - å®Œæ•´çš„ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ  
âœ… **å¯æ‰©å±•æ€§** - æ˜“äºæ·»åŠ æ–°çš„æä¾›å•†

è¯¥æ¶æ„ä¸ºæ„å»ºå¤æ‚çš„ AI Agent åº”ç”¨æä¾›äº†åšå®çš„åŸºç¡€ã€‚
